#!/usr/bin/env python3
"""
æœ€ç®€å•çš„RK3588 ONNXå¯¼å‡ºæ–¹æ¡ˆ
åŠ¨æ€æ›¿æ¢æ£€æµ‹å¤´çš„forwardæ–¹æ³•ï¼Œæ— éœ€ä¿®æ”¹æºç 
"""

import torch
import torch.nn as nn
from ultralytics import YOLO
import types
import argparse
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')


def create_rk3588_forward(detect_head):
    """ä¸ºæ£€æµ‹å¤´åˆ›å»ºRK3588é£æ ¼çš„forwardæ–¹æ³•"""
    
    # åˆ›å»ºconv1x1å±‚ - æŒ‰ç…§yolov8_train_inf.mdç¬¬120-122è¡Œ
    conv1x1 = nn.Conv2d(16, 1, 1, bias=False).requires_grad_(False)
    x = torch.arange(16, dtype=torch.float)
    conv1x1.weight.data[:] = nn.Parameter(x.view(1, 16, 1, 1))
    
    # å°†conv1x1æ·»åŠ åˆ°æ£€æµ‹å¤´
    detect_head.conv1x1 = conv1x1
    
    def rk3588_forward(self, x):
        """å®Œå…¨å¤åˆ¶yolov8_train_inf.mdç¬¬125-134è¡Œçš„forwardé€»è¾‘"""
        y = []
        for i in range(self.nl):
            t1 = self.cv2[i](x[i])  # å›å½’åˆ†æ”¯
            t2 = self.cv3[i](x[i])  # åˆ†ç±»åˆ†æ”¯ï¼ˆä¿æŒlogitsæ ¼å¼ï¼Œä¸åŠ sigmoidï¼‰
            
            # å®Œå…¨å¤åˆ¶æ–‡æ¡£ç¬¬132è¡Œçš„DFLå¤„ç†é€»è¾‘
            dfl_processed = self.conv1x1(
                t1.view(t1.shape[0], 4, 16, -1)  # reshape to [batch, 4, 16, H*W]
                .transpose(2, 1)                  # transpose to [batch, 16, 4, H*W]
                .softmax(1)                      # softmax on 16 distributions
            )  # conv1x1: [batch, 1, 4, H*W]
            
            # RK3588 æœŸæœ›çš„å›å½’è¾“å‡ºå¸ƒå±€ï¼šä¿æŒæ‰å¹³åŒ– [batch, 1, 4, H*W]
            reg_output = dfl_processed
            
            y.append(reg_output)  # regN
            y.append(t2)         # clsN
        
        return y
    
    return rk3588_forward


def export_rk3588_onnx(model_path, output_path=None):
    """å¯¼å‡ºRK3588ä¼˜åŒ–çš„ONNXæ¨¡å‹"""
    
    if output_path is None:
        model_stem = Path(model_path).stem
        output_path = f"{model_stem}_rk3588_simple.onnx"
    
    print(f"ğŸ“¦ åŠ è½½YOLOæ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    
    # è®¾ç½®æ¨¡å‹ä¸ºæ¨ç†æ¨¡å¼
    model.model.eval()
    model.model.float()
    
    # è·å–æ£€æµ‹å¤´
    detect_head = model.model.model[-1]
    print(f"âœ“ æ£€æµ‹å¤´ç±»å‹: {type(detect_head)}")
    print(f"âœ“ æ£€æµ‹å±‚æ•°: {detect_head.nl}")
    print(f"âœ“ ç±»åˆ«æ•°: {detect_head.nc}")
    
    # åŠ¨æ€æ›¿æ¢forwardæ–¹æ³•
    print(f"ğŸ”„ æ›¿æ¢æ£€æµ‹å¤´forwardæ–¹æ³•...")
    new_forward = create_rk3588_forward(detect_head)
    detect_head.forward = types.MethodType(new_forward, detect_head)
    
    # æµ‹è¯•æ¨¡å‹
    print(f"ğŸ§ª æµ‹è¯•ä¿®æ”¹åçš„æ¨¡å‹...")
    dummy_input = torch.randn(1, 3, 640, 640)
    
    with torch.no_grad():
        try:
            outputs = model.model(dummy_input)
            print(f"âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œè¾“å‡ºæ•°é‡: {len(outputs)}")
            for i, out in enumerate(outputs):
                print(f"  è¾“å‡º{i}: {list(out.shape)}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            return
    
    # æŒ‰ç…§yolov8_train_inf.mdç¬¬192-195è¡Œè®¾ç½®è¾“å…¥è¾“å‡ºåç§°
    input_names = ["data"]
    output_names = ["reg1", "cls1", "reg2", "cls2", "reg3", "cls3"]
    
    print(f"ğŸ”„ å¯¼å‡ºONNXæ¨¡å‹åˆ°: {output_path}")
    torch.onnx.export(
        model.model,
        dummy_input,
        output_path,
        verbose=False,
        input_names=input_names,
        output_names=output_names,
        opset_version=11,
        do_constant_folding=True,
        # å›ºå®šbatch=1ï¼Œä¸ä¾µå…¥å¼æ–¹æ³•ä¿æŒå®Œå…¨ä¸€è‡´
        dynamic_axes=None
    )
    
    print(f"âœ… RK3588 ONNXå¯¼å‡ºæˆåŠŸ: {output_path}")
    
    # éªŒè¯ONNXæ¨¡å‹
    try:
        import onnxruntime as ort
        print(f"ğŸ§ª éªŒè¯ONNXæ¨¡å‹...")
        session = ort.InferenceSession(output_path, providers=['CPUExecutionProvider'])
        
        print("\nğŸ“Š ONNXæ¨¡å‹ä¿¡æ¯:")
        print("è¾“å…¥:")
        for inp in session.get_inputs():
            print(f"  {inp.name}: {inp.shape} ({inp.type})")
        
        print("è¾“å‡º:")
        for out in session.get_outputs():
            print(f"  {out.name}: {out.shape} ({out.type})")
        
        # æµ‹è¯•æ¨ç†å¯¹æ¯”
        print(f"\nğŸ¯ æ¨ç†å¯¹æ¯”æµ‹è¯•:")
        input_data = dummy_input.numpy()
        
        # ONNXæ¨ç†
        onnx_outputs = session.run(None, {input_names[0]: input_data})
        print("ONNXè¾“å‡º:")
        for i, (name, output) in enumerate(zip(output_names, onnx_outputs)):
            print(f"  {name}: {output.shape}, æ•°å€¼èŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
        
        # PTæ¨ç†
        with torch.no_grad():
            pt_outputs = model.model(dummy_input)
        print("PTè¾“å‡º:")
        for i, output in enumerate(pt_outputs):
            output_np = output.numpy()
            name = output_names[i]
            print(f"  {name}: {output_np.shape}, æ•°å€¼èŒƒå›´: [{output_np.min():.4f}, {output_np.max():.4f}]")
        
    except ImportError:
        print("âš ï¸ æœªå®‰è£…onnxruntimeï¼Œè·³è¿‡éªŒè¯")
    except Exception as e:
        print(f"âš ï¸ ONNXéªŒè¯å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description='Simple RK3588 ONNX Export')
    parser.add_argument('model', help='Path to YOLOv8 model (.pt file)')
    parser.add_argument('-o', '--output', help='Output ONNX file path')
    
    args = parser.parse_args()
    
    # å¯¼å‡ºRK3588ä¼˜åŒ–çš„ONNX
    export_rk3588_onnx(args.model, args.output)


if __name__ == "__main__":
    main()